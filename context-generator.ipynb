{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from deep_translator import GoogleTranslator\n",
    "from deep_translator.exceptions import TranslationNotFound\n",
    "\n",
    "from src.gotify_functions import send_gotify_notification\n",
    "from src.data_utils.json_utils import read_json_file, save_json\n",
    "from src.time_utils.time_formatters import format_time\n",
    "from src.api_utils.http_requests_custom import make_post_request\n",
    "from src.api_utils.response_parsers import extract_json_responses\n",
    "from src.qa_tools.data_processing import count_answer_types_qas, count_answer_types_SQuAD\n",
    "from src.data_processing.validation import validate_squad_format\n",
    "from src.data_processing.dataset_utils import reshuffle_questions"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==== Configuration ====\n",
    "\n",
    "API_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL = \"llama3.3:latest\"\n",
    "LANGS = ['en', 'de', 'fr']\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\")\n",
    "PROMPTS = read_json_file(os.path.join(PROJECT_ROOT, \"prompts.json\"))\n",
    "COMPANIES = read_json_file(os.path.join(DATA_PATH, \"placeholders/companies.json\"))[\"companies\"]"
   ],
   "id": "d834ddcf4bd8e89a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==== Prompt Generation ====\n",
    "def generate_random_prompt(prompt_type, lang, sample):\n",
    "    \"\"\"Generates a random prompt based on type, language, and provided sample.\"\"\"\n",
    "    prompt_templates = PROMPTS[prompt_type][lang]\n",
    "    selected_prompt = random.choice(prompt_templates)\n",
    "    company = np.random.choice(COMPANIES)\n",
    "    return selected_prompt.format(sample=sample, company=company)\n",
    "\n",
    "def pick_question_prompt(prompt_type, lang, context, prompt_num=0, num_questions=10):\n",
    "    selected_prompt = PROMPTS[\"question_generate\"][prompt_type][lang][prompt_num]\n",
    "    qa_format = PROMPTS[\"question_generate\"][\"qa_format\"]\n",
    "    return selected_prompt.format(context=context, num_questions=num_questions, qa_format=qa_format)"
   ],
   "id": "167ad3d1d2c92489"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==== QA Extraction from response ====\n",
    "def extract_qas(response, lang, translators, answer_type):\n",
    "    json_pattern = r'\\{[\\s\\S]*?\"qa\":\\s*\\[[\\s\\S]*?\\][\\s\\S]*?\\}'\n",
    "    match = re.search(json_pattern, response)\n",
    "    if not match:\n",
    "        print(\"No JSON data found.\")\n",
    "        return []\n",
    "    try:\n",
    "        parsed_data = json.loads(match.group(0))\n",
    "        qas_list = []\n",
    "        for qa in parsed_data.get('qa', []):\n",
    "            answer = qa['a']\n",
    "            qa_dict = {\n",
    "                \"question\": qa['q'],\n",
    "                \"answer\": answer.strip() if isinstance(answer, str) else answer,\n",
    "                \"answer_type\": answer_type,\n",
    "                \"lang\": lang\n",
    "            }\n",
    "            qas_list.append(qa_dict)\n",
    "            # Translate the question into other languages\n",
    "            for translator in translators:\n",
    "                try:\n",
    "                    qas_list.append({\n",
    "                        \"question\": translator.translate(qa_dict[\"question\"]),\n",
    "                        \"answer\": qa_dict[\"answer\"],\n",
    "                        \"answer_type\": answer_type,\n",
    "                        \"lang\": translator.target\n",
    "                    })\n",
    "                except TranslationNotFound:\n",
    "                    print(\n",
    "                        f\"Error: Translation not found.\\n\"\n",
    "                        f\"Question: {qa_dict['question']}\\n\"\n",
    "                        f\"Continuing the execution\"\n",
    "                    )\n",
    "        return qas_list\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error decoding JSON:\", e)\n",
    "        print(response)\n",
    "        print(\"------------------------------\")\n",
    "        return []"
   ],
   "id": "eb71776d5120884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==== Main Data Generation ====\n",
    "def main():\n",
    "    source_dataset = read_json_file(os.path.join(DATA_PATH, \"raw/synthetic_data_1000.json\"))\n",
    "    start_idx, end_idx = 328, 500\n",
    "\n",
    "    progress = tqdm(total=end_idx-start_idx, desc=\"Generating contexts\", dynamic_ncols=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for entry in source_dataset[start_idx:end_idx]:\n",
    "        translated_entry = {\"sample\": entry[\"sample\"], \"context\": {}}\n",
    "        translated_entry[\"context\"][\"en\"] = entry[\"text\"].strip()\n",
    "\n",
    "        # Generate context for FR and DE\n",
    "        for lang in [\"fr\", \"de\"]:\n",
    "            prompt = generate_random_prompt(\"context_generate\", lang.upper(), entry['sample'])\n",
    "            translated_entry[\"context\"][lang] = extract_json_responses(make_post_request(prompt, MODEL, API_URL)).strip()\n",
    "\n",
    "        # Save to file\n",
    "        out_path = os.path.join(DATA_PATH, \"raw/synthetic_data_300_multilingual.json\")\n",
    "        if os.path.exists(out_path):\n",
    "            data_from_file = read_json_file(out_path)\n",
    "            merged_data = {'data': data_from_file[\"data\"] + [translated_entry]}\n",
    "        else:\n",
    "            merged_data = {'data': [translated_entry]}\n",
    "        save_json(out_path, merged_data)\n",
    "\n",
    "        progress.update(1)\n",
    "\n",
    "    progress.close()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_iter = elapsed_time / (end_idx - start_idx)\n",
    "    print(f\"Generating contexts completed\\nTotal: {progress.n}/{end_idx-start_idx}\\nElapsed: {elapsed_time:.2f}s\\nAvg/iter: {avg_time_per_iter:.2f}s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "44c101bbf7eb21c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
