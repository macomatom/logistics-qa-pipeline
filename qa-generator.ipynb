{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from deep_translator import GoogleTranslator\n",
    "from deep_translator.exceptions import TranslationNotFound\n",
    "\n",
    "from src.gotify_functions import send_gotify_notification\n",
    "from src.data_utils.json_utils import read_json_file, save_json\n",
    "from src.time_utils.time_formatters import format_time\n",
    "from src.api_utils.http_requests_custom import make_post_request\n",
    "from src.api_utils.response_parsers import extract_json_responses\n",
    "from src.qa_tools.data_processing import count_answer_types_qas, count_answer_types_SQuAD\n",
    "from src.data_processing.validation import validate_squad_format\n",
    "from src.data_processing.dataset_utils import reshuffle_questions"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==== Configuration ====\n",
    "\n",
    "API_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL = \"llama3.3:latest\"\n",
    "LANGS = ['en', 'de', 'fr']\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\")\n",
    "PROMPTS = read_json_file(os.path.join(PROJECT_ROOT, \"prompts.json\"))\n",
    "COMPANIES = read_json_file(os.path.join(DATA_PATH, \"placeholders/companies.json\"))[\"companies\"]"
   ],
   "id": "cac38a7f24473299"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_random_prompt(prompt_type, lang, sample):\n",
    "    \"\"\"Generates a random prompt based on type, language, and provided sample.\"\"\"\n",
    "    try:\n",
    "        prompt_templates = PROMPTS[prompt_type][lang]\n",
    "        selected_prompt = random.choice(prompt_templates)\n",
    "        company = np.random.choice(COMPANIES)\n",
    "        return selected_prompt.format(sample=sample, company=company)\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Invalid prompt type or language: {e}\")\n",
    "\n",
    "path = os.path.join(DATA_PATH, \"raw/synthetic_data_1000.json\")\n",
    "source_dataset = read_json_file(path)\n",
    "generate_random_prompt(\"context_generate\", \"FR\", source_dataset[0]['sample'])\n",
    "\n",
    "def pick_question_prompt(prompt_type, lang, context, prompt_num=0, num_questions=10):\n",
    "    \"\"\"Generates a random prompt based on type, language, and provided sample.\"\"\"\n",
    "    try:\n",
    "        selected_prompt = PROMPTS[\"question_generate\"][prompt_type][lang][prompt_num]\n",
    "        qa_format = PROMPTS[\"question_generate\"][\"qa_format\"]\n",
    "        return selected_prompt.format(context=context, num_questions=num_questions, qa_format=qa_format)\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Invalid prompt type or language: {e}\")"
   ],
   "id": "2fb5c82e7b288aba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check for unwanted answers in square brackets\n",
    "def is_square_brackets_answer(answer):\n",
    "    matches = re.findall(r'\\[[^\"\\[\\]]*\\]', answer)\n",
    "    return (len(matches) > 0)\n",
    "\n",
    "def extract_qas(response, lang, translators, answer_type):\n",
    "#     json_pattern = r'{.*}'\n",
    "    json_pattern = r'\\{[\\s\\S]*?\"qa\":\\s*\\[[\\s\\S]*?\\][\\s\\S]*?\\}'\n",
    "#     match = re.search(json_pattern, response, re.DOTALL)\n",
    "    match = re.search(json_pattern, response)\n",
    "    if not match:\n",
    "        print(\"No JSON data found.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        parsed_data = json.loads(match.group(0))\n",
    "#         print(parsed_data)\n",
    "        qas_list = []\n",
    "        for qa in parsed_data.get('qa', []):\n",
    "            answer = qa['a']\n",
    "            qa_dict = {\n",
    "                \"question\": qa['q'],\n",
    "                \"answer\": answer.strip() if isinstance(answer, str) else answer,\n",
    "                \"answer_type\": answer_type,\n",
    "                \"lang\": lang\n",
    "            }\n",
    "            qas_list.append(qa_dict)\n",
    "\n",
    "            # Translate the question into other languages\n",
    "            for translator in translators:\n",
    "                try:\n",
    "                    qas_list.append({\n",
    "                        \"question\": translator.translate(qa_dict[\"question\"]),\n",
    "                        \"answer\": qa_dict[\"answer\"],  # Answer remains in original language\n",
    "                        \"answer_type\": answer_type,\n",
    "                        \"lang\": translator.target\n",
    "                    })\n",
    "                except TranslationNotFound:\n",
    "                    send_gotify_notification(\n",
    "                        f\"Error: Translation not found.\\n\"\n",
    "                        f\"Question: {qa_dict['question']}\\n\"\n",
    "                        f\"Continuing the execution\"\n",
    "                    )\n",
    "\n",
    "        return qas_list\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error decoding JSON:\", e)\n",
    "        print(response)\n",
    "        print(\"------------------------------\")\n",
    "        return []\n",
    "\n",
    "def process_entry(item, langs, prompt_number=0):\n",
    "    new_dict_item = {\n",
    "        \"sample\": item[\"sample\"],\n",
    "        \"context\": item[\"context\"],\n",
    "        \"qas\": {}\n",
    "    }\n",
    "    for lang in langs:\n",
    "        prompt = pick_question_prompt(\"general\", lang, item['context'][lang], prompt_num=prompt_number)  # Generate questions for the given language\n",
    "        response = extract_json_responses(make_post_request(prompt, MODEL, API_URL)).strip()\n",
    "        translators = [GoogleTranslator(source=lang, target=other) for other in langs if other != lang]\n",
    "        new_dict_item[\"qas\"][lang] = extract_qas(response, lang, translators, answer_type=\"string\")  # Generate questions for the given language\n",
    "    return new_dict_item"
   ],
   "id": "151df9c214720632"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MODEL = \"llama3.3:latest\"\n",
    "\n",
    "# Load input and output data files\n",
    "data_from_file = read_json_file(\"synthetic_data_500_multilingual.json\")\n",
    "output_file_name = \"synthetic_data_500_multilingual_qas.json\"\n",
    "\n",
    "data = {}\n",
    "data['data'] = []\n",
    "num_total_errors = 0\n",
    "\n",
    "start_idx, end_idx = 459, 500  # Define the range of data entries to process\n",
    "progress = tqdm(total=end_idx-start_idx, desc=\"Generovanie otazok a odpovedi\", position=0, leave=True, dynamic_ncols=True)\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Extract relevant portion of the dataset\n",
    "    data_slice = data_from_file['data'][start_idx:end_idx]\n",
    "    output_data = read_json_file(output_file_name)['data']\n",
    "\n",
    "    for i, item in enumerate(data_slice):\n",
    "        new_dict_item = process_entry(item, LANGS, 0)  # Process each item to generate Q&A pairs\n",
    "        output_data.append(new_dict_item)\n",
    "        save_json(output_file_name, {'data': output_data})  # Save the updated dataset\n",
    "        progress.update(1)\n",
    "\n",
    "        # Send periodic status update every 10 iterations\n",
    "        if (i + 1) % 10 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            send_gotify_notification(\n",
    "                f\"Progress Update: {progress.n}/{end_idx-start_idx} iterations completed.\\n\"\n",
    "                f\"Elapsed time: {format_time(elapsed_time)}\"\n",
    "            )\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_iter = elapsed_time / (end_idx-start_idx)\n",
    "\n",
    "    # Send completion notification\n",
    "    send_gotify_notification(\n",
    "        f\"Generating questions completed\\n\"\n",
    "        f\"Total iterations: {progress.n}/{end_idx-start_idx}\\n\"\n",
    "        f\"Elapsed time: {format_time(elapsed_time)}\\n\"\n",
    "        f\"Avg time per iteration: {format_time(avg_time_per_iter)}\"\n",
    "    )\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors and send notification\n",
    "    error_message = f\"Error occurred: {str(e)}\\n{traceback.format_exc()}\"\n",
    "    send_gotify_notification(error_message)\n",
    "    print(error_message)  # Optional: Also print to console\n",
    "\n",
    "finally:\n",
    "    # Close progressbar even if an error occurs\n",
    "    progress.close()  # âœ… Explicitly close tqdm"
   ],
   "id": "d58bf745280aac36"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
